{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas.\n",
    "\n",
    "import glob\n",
    "import natsort\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data field names\n",
    "Column names and the names of the variables we want to extract slightly vary between countries. Hence, first we define the column names of the _date_ column, _variable_ and _national total_ columns as well as the names of the fields for each country.\n",
    "\n",
    "In addition to new cases and total deaths, we also extract the data correponding to new deaths , total cases and total deaths aggregated over all couties to cross-check the data. \n",
    "\n",
    "For new and total deaths and cases, respectively, we chose to extract confirmed values which seem most reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe importing \n",
    "# Colums: country, month, averagy, new cases, death\n",
    "\n",
    "# column names and interesting variables for each country\n",
    "\n",
    "# column name of the date column\n",
    "col_date = {\"guinea\" : \"Date\",\n",
    "            \"liberia\": \"Date\",\n",
    "            \"sl\" : \"date\"} \n",
    "\n",
    "# column name of the indicator variables to extract according to country\n",
    "# column containing the variables\n",
    "col_name={\"guinea\" : \"Description\",\n",
    "          \"liberia\": \"Variable\",\n",
    "          \"sl\" : \"variable\"} \n",
    "# column containing national totals\n",
    "col_total = {\"guinea\":\"Totals\",\n",
    "             \"liberia\":\"National\",\n",
    "             \"sl\": \"National\"} # column name where the national totals per day are stored\n",
    "\n",
    "# counties\n",
    "col_counties={\"guinea\":[\"Conakry\",\"Gueckedou\",\"Macenta\",\"Dabola\",\"Kissidougou\",\"Dinguiraye\",\n",
    "                        \"Telimele\",\"Boffa\",\"Kouroussa\",\"Siguiri\",\"Pita\",\"Nzerekore\",\"Yomou\",\n",
    "                        \"Dubreka\",\"Forecariah\",\"Kerouane\",\"Coyah\",\"Dalaba\",\"Beyla\",\"Kindia\"],\n",
    "              \"liberia\":[\"Bomi County\",\"Bong County\",\"Grand Kru\",\"Lofa County\",\"Margibi County\",\n",
    "                         \"Maryland County\",\"Montserrado County\",\"Nimba County\",\"River Gee County\",\n",
    "                         \"RiverCess County\",\"Sinoe County\"],\n",
    "              \"sl\":[\"Kailahun\",\"Kenema\",\"Kono\",\"Kambia\",\"Koinadugu\",\"Bombali\",\"Tonkolili\",\"Port Loko\",\n",
    "                    \"Pujehun\",\"Bo\",\"Moyamba\",\"Bonthe\",\"Western area urban\",\"Western area rural\"]}\n",
    "\n",
    "\n",
    "# rows names to extract according to country\n",
    "# new deaths\n",
    "var_death_new =  {\"guinea\" : [\"New deaths registered today (confirmed)\",\"New deaths registered\"], \n",
    "                  # in the case of Guinea, the row names for new deaths differ\n",
    "             \"liberia\": [\"Newly reported deaths\"],# \"Total death/s in confirmed cases\"\n",
    "             \"sl\":[\"etc_new_deaths\"]}\n",
    "\n",
    "# total deaths\n",
    "var_death_total =  {\"guinea\" : [\"Total deaths of confirmed\"],\n",
    "             \"liberia\": [\"Total death/s in confirmed cases\"],# \"Total death/s in confirmed cases\"\n",
    "             \"sl\":[\"death_confirmed\"]}\n",
    "\n",
    "# new cases\n",
    "var_cases_new = {\"guinea\" : [\"New cases of confirmed\"],\n",
    "             \"liberia\": [\"New case/s (confirmed)\"],\n",
    "             \"sl\":[\"new_confirmed\"]}\n",
    "\n",
    "# total cases\n",
    "var_cases_tot = {\"guinea\" : [\"Total cases of confirmed\"],\n",
    "             \"liberia\": [\"Total confirmed cases\"],\n",
    "             \"sl\":[\"cum_confirmed\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate data frames\n",
    "Now, we loop over all files and import them, applying necessary clean-up operations.\n",
    "\n",
    "For each country and for each date, we extract the interresting values that are cleaned up (type conversions, comma stripping etc...). They are dataframes with only one row that look like this one: \n",
    "<img src='imgs/1.png'>\n",
    "\n",
    "All those DataFrames are in the list `dfs` and eventually merged in `df` by paying attention to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>New Cases</th>\n",
       "      <th>New Deaths</th>\n",
       "      <th>Total Cases</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Deaths Counties</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">guinea</th>\n",
       "      <th>2014-08-04</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>351</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-26</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>490</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-27</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>499</td>\n",
       "      <td>294</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-30</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>533</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-31</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>563</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    New Cases  New Deaths  Total Cases  Total Deaths  \\\n",
       "Country Date                                                           \n",
       "guinea  2014-08-04          4           2          351           228   \n",
       "        2014-08-26         10           5          490           292   \n",
       "        2014-08-27         10           2          499           294   \n",
       "        2014-08-30          9           5          533           324   \n",
       "        2014-08-31         29           3          563           337   \n",
       "\n",
       "                    Total Deaths Counties  \n",
       "Country Date                               \n",
       "guinea  2014-08-04                    228  \n",
       "        2014-08-26                    292  \n",
       "        2014-08-27                    267  \n",
       "        2014-08-30                    324  \n",
       "        2014-08-31                    337  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [] # this is a list of dataframes (one for each day)\n",
    "for c in ['guinea','liberia','sl']:\n",
    "    for file in sorted(glob.glob(DATA_FOLDER+\"/ebola/\"+c+\"_data/*.csv\")): #going through all the files\n",
    "        df = pd.read_csv(file,index_col=None)\n",
    "        df = df.fillna(0) # Fill NA values\n",
    "        \n",
    "        # Get Data\n",
    "        columns=[col_date[c],col_name[c],col_total[c]]\n",
    "        \n",
    "        # Dates\n",
    "        date = pd.to_datetime(df[1:2][col_date[c]]) # dates\n",
    "        \n",
    "        # New cases\n",
    "        # Extract only relevant rows for new cases\n",
    "        df_cases_new = df[df[col_name[c]].isin(var_cases_new[c])]\n",
    "        # Extract only relevant columns (date - name - total)\n",
    "        df_cases_new = df_cases_new[columns]\n",
    "        # Strip commas for 1000s\n",
    "        df_cases_new[0:1][col_total[c]].values[0] = str(df_cases_new[0:1][col_total[c]].values[0]).replace(',','')\n",
    "        # Convert to int (e.g., 10.0 or 10,0)\n",
    "        df_cases_new[col_total[c]] = df_cases_new[col_total[c]].astype(int)\n",
    "        # Cases\n",
    "        cases_new = int(df_cases_new[0:1][col_total[c]])\n",
    "        \n",
    "        # Total cases\n",
    "        # Extract only relevant rows for total cases\n",
    "        df_cases_total = df[df[col_name[c]].isin(var_cases_tot[c])]\n",
    "        # Extract only relevant columns (date - name - total)\n",
    "        df_cases_total = df_cases_total[columns]\n",
    "        # Strip commas for 1000s\n",
    "        df_cases_total[0:1][col_total[c]].values[0] = str(df_cases_total[0:1][col_total[c]].values[0]).replace(',','')\n",
    "        # Convert to int (e.g., 10.0 or 10,0)\n",
    "        df_cases_total[col_total[c]] = df_cases_total[col_total[c]].astype(int)\n",
    "        # Cases\n",
    "        cases_total = int(df_cases_total[0:1][col_total[c]])\n",
    "\n",
    "        # New deaths\n",
    "        # Extract only relevant rows\n",
    "        df_deaths_new = df[df[col_name[c]].isin(var_death_new[c])]\n",
    "        # Extract only relevant columns (date - name - total)\n",
    "        df_deaths_new = df_deaths_new[columns]\n",
    "        # Deaths \n",
    "        deaths_new = int(df_deaths_new[0:1][col_total[c]])\n",
    "        \n",
    "        # Total Deaths\n",
    "        # Extract only relevant rows\n",
    "        df_deaths_total = df[df[col_name[c]].isin(var_death_total[c])]\n",
    "        # Extract only relevant columns (date - name - total)\n",
    "        df_deaths_total = df_deaths_total[columns]\n",
    "        # Deaths\n",
    "        deaths_total = int(df_deaths_total[0:1][col_total[c]]) \n",
    "        \n",
    "        # Total Deaths by County\n",
    "        # Extract only relevant rows\n",
    "        df_deaths_total_county_sum = df[df[col_name[c]].isin(var_death_total[c])] \n",
    "        cols=list(set(df.columns.values).difference(columns))\n",
    "        # Extract only relevant columns (date - name - total)\n",
    "        df_deaths_total_county_sum = df_deaths_total_county_sum[cols]\n",
    "        for col in df_deaths_total_county_sum.columns:\n",
    "            df_deaths_total_county_sum[col]=df_deaths_total_county_sum[col].astype(int)\n",
    "        deaths_total_county_sum = np.nansum(df_deaths_total_county_sum.values)\n",
    "        \n",
    "        # New dataframe from data (one row per date)\n",
    "        df = pd.DataFrame({\"Country\":c,\"Date\":date,\"New Cases\":cases_new,\"Total Cases\":cases_total,\"New Deaths\":deaths_new,\"Total Deaths\":deaths_total,\"Total Deaths Counties\":deaths_total_county_sum},index=None)\n",
    "        dfs.append(df)\n",
    "        \n",
    "for i in range(len(dfs)-1): # concatenate all dataframes (rows)\n",
    "    dfs[0] = pd.concat([dfs[0],dfs[i+1]])\n",
    "df=dfs[0]\n",
    "\n",
    "df=df.sort_values(by=['Country','Date']) # sort by country and date\n",
    "df=df.set_index(['Country','Date']) # new index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a discrepancy between the new deaths (confirmed) and the total deaths (confirmed), as the new cases /deaths don't add up to the cumsum of the total cases / deaths of the next date. Maybe the data doesn't come from the same source or there is missing data. \n",
    "\n",
    "Also, the total deaths don't always quite add up with the sum of deaths per county, which may be due to incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>New Cases</th>\n",
       "      <th>New Deaths</th>\n",
       "      <th>Total Cases</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Total Deaths Counties</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sl</th>\n",
       "      <th>2014-12-01</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>5978</td>\n",
       "      <td>1549</td>\n",
       "      <td>1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-04</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>6238</td>\n",
       "      <td>1648</td>\n",
       "      <td>1648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-05</th>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>6292</td>\n",
       "      <td>1669</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6317</td>\n",
       "      <td>1708</td>\n",
       "      <td>1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6638</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    New Cases  New Deaths  Total Cases  Total Deaths  \\\n",
       "Country Date                                                           \n",
       "sl      2014-12-01         72           0         5978          1549   \n",
       "        2014-12-04         37           3         6238          1648   \n",
       "        2014-12-05         54           8         6292          1669   \n",
       "        2014-12-06          0           0         6317          1708   \n",
       "        2014-12-13          0           0         6638             0   \n",
       "\n",
       "                    Total Deaths Counties  \n",
       "Country Date                               \n",
       "sl      2014-12-01                   1549  \n",
       "        2014-12-04                   1648  \n",
       "        2014-12-05                   1669  \n",
       "        2014-12-06                   1708  \n",
       "        2014-12-13                      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data checking\n",
    "\n",
    "Let's check the data whether the index is unique and whether there are still NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index unique:\n",
      "True\n",
      "New Cases:\n",
      "0\n",
      "New Deaths:\n",
      "0\n",
      "Total Cases:\n",
      "0\n",
      "Total Deaths:\n",
      "0\n",
      "Total Deaths Counties:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Data checking\n",
    "print(\"Index unique:\")\n",
    "print(df.index.is_unique) # True\n",
    "for col in df.columns:\n",
    "    print(col+\":\")\n",
    "    print(df[df[col].isnull()].size) # get NaN colums (all 0)\n",
    "    \n",
    "df=df.reset_index() # for next part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate by month\n",
    "\n",
    "Now, we can regroup the data by month and sums each column by the month. Then, we rename the date column as month column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean New Cases</th>\n",
       "      <th>Mean New Deaths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">guinea</th>\n",
       "      <th>8</th>\n",
       "      <td>12.40</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.00</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">liberia</th>\n",
       "      <th>6</th>\n",
       "      <td>2.14</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.82</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.44</td>\n",
       "      <td>23.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.17</td>\n",
       "      <td>36.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.36</td>\n",
       "      <td>28.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.60</td>\n",
       "      <td>13.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1928.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sl</th>\n",
       "      <th>8</th>\n",
       "      <td>18.55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34.41</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>56.71</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>59.90</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32.60</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean New Cases  Mean New Deaths\n",
       "Country Month                                 \n",
       "guinea  8               12.40             3.40\n",
       "        9               13.00             3.56\n",
       "        10               6.00            15.00\n",
       "liberia 6                2.14             2.00\n",
       "        7                1.82             4.27\n",
       "        8                5.44            23.22\n",
       "        9                6.17            36.04\n",
       "        10               1.36            28.04\n",
       "        11               2.60            13.47\n",
       "        12            1928.33             0.00\n",
       "sl      8               18.55             0.00\n",
       "        9               34.41             0.28\n",
       "        10              56.71             3.54\n",
       "        11              59.90             0.57\n",
       "        12              32.60             2.20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate by month\n",
    "\n",
    "df_month = pd.DataFrame(df[[\"Country\",\"Date\",\"New Cases\",\"New Deaths\"]].groupby([df.Country,df.Date.dt.month]).mean()).reset_index()\n",
    "df_month.columns=[\"Country\",\"Month\",\"Mean New Cases\",\"Mean New Deaths\"]\n",
    "df_month = df_month.set_index(['Country','Month'])\n",
    "df_month.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like Ebola peaked around September in Guinea, around August-October in Liberia and around October-November in Sierra Leone.\n",
    "\n",
    "_suspicious_: no deaths in November and December in Liberia but many new cases. Maybe erroneous data or breakout of a new epidemia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Add column for NaN and number of days\n",
    "# For mean, exclude mean\n",
    "# Ignore December in Liberia and explain why\n",
    "# Cure Ebola ðŸ¦„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Merging\n",
    "First we merge all data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARCODE</th>\n",
       "      <th>Species</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">MID1</th>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Pyrodictiaceae Pyrolobus</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Sulfolobales Sulfolobaceae Stygiolobus</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Thermoproteales Thermofilaceae Thermofilum</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Euryarchaeota\" \"Methanomicrobia\" Methanocellales Methanocellaceae Methanocella</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Count\n",
       "BARCODE Species                                                  \n",
       "MID1    Archaea \"Crenarchaeota\" Thermoprotei Desulfuroc...      7\n",
       "        Archaea \"Crenarchaeota\" Thermoprotei Desulfuroc...      2\n",
       "        Archaea \"Crenarchaeota\" Thermoprotei Sulfolobal...      3\n",
       "        Archaea \"Crenarchaeota\" Thermoprotei Thermoprot...      3\n",
       "        Archaea \"Euryarchaeota\" \"Methanomicrobia\" Metha...      7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer here\n",
    "\n",
    "# Read in Excel files, concatenate them and add file name (MID1...9) for later merging\n",
    "dfs=[]\n",
    "for i in range(1,10):\n",
    "    MID_tmp=pd.read_excel(DATA_FOLDER+'/microbiome/MID'+str(i)+'.xls', sheetname='Sheet 1', header=None,index_col=0)\n",
    "    MID_tmp.columns=['Count']\n",
    "    MID_tmp['BARCODE'] = \"MID\"+str(i)  # add column with file name\n",
    "    # new dataframe from data\n",
    "    dfs.append(MID_tmp)\n",
    "        \n",
    "for i in range(len(dfs)-1): # concatenate all dataframes\n",
    "    dfs[0] = pd.concat([dfs[0],dfs[i+1]])\n",
    "\n",
    "MID=dfs[0]\n",
    "MID.index.name=\"Species\"\n",
    "MID=MID.reset_index()\n",
    "MID=MID.set_index([\"BARCODE\",\"Species\"])\n",
    "MID.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata import and Merging\n",
    "We can now import the metadata and merge the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARCODE</th>\n",
       "      <th>Species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">MID1</th>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera</th>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Pyrodictiaceae Pyrolobus</th>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Sulfolobales Sulfolobaceae Stygiolobus</th>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Crenarchaeota\" Thermoprotei Thermoproteales Thermofilaceae Thermofilum</th>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archaea \"Euryarchaeota\" \"Methanomicrobia\" Methanocellales Methanocellaceae Methanocella</th>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>unknown</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         GROUP  \\\n",
       "BARCODE Species                                                                  \n",
       "MID1    Archaea \"Crenarchaeota\" Thermoprotei Desulfuroc...  EXTRACTION CONTROL   \n",
       "        Archaea \"Crenarchaeota\" Thermoprotei Desulfuroc...  EXTRACTION CONTROL   \n",
       "        Archaea \"Crenarchaeota\" Thermoprotei Sulfolobal...  EXTRACTION CONTROL   \n",
       "        Archaea \"Crenarchaeota\" Thermoprotei Thermoprot...  EXTRACTION CONTROL   \n",
       "        Archaea \"Euryarchaeota\" \"Methanomicrobia\" Metha...  EXTRACTION CONTROL   \n",
       "\n",
       "                                                             SAMPLE  Count  \n",
       "BARCODE Species                                                             \n",
       "MID1    Archaea \"Crenarchaeota\" Thermoprotei Desulfuroc...  unknown      7  \n",
       "        Archaea \"Crenarchaeota\" Thermoprotei Desulfuroc...  unknown      2  \n",
       "        Archaea \"Crenarchaeota\" Thermoprotei Sulfolobal...  unknown      3  \n",
       "        Archaea \"Crenarchaeota\" Thermoprotei Thermoprot...  unknown      3  \n",
       "        Archaea \"Euryarchaeota\" \"Methanomicrobia\" Metha...  unknown      7  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read metadata\n",
    "metadata = pd.read_excel(DATA_FOLDER+'/microbiome/metadata.xls', sheetname='Sheet1',index_col=0)\n",
    "\n",
    "# merge metadata and files\n",
    "MID_merged = pd.merge(metadata, MID, left_index=True, right_index=True)#, on=\"BARCODE\")\n",
    "MID_merged=MID_merged.fillna(\"unknown\")\n",
    "MID_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(DATA_FOLDER+'/titanic.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "* pclass: integers, values in {1, 2, 3} depending on the class. This is a `categorical` attribute.\n",
    "* survived: integers, values in {0 ,1} depending on whether the person survived. This is a `categorical` attribute.\n",
    "* name: string\n",
    "* sex: string, values in {male, female}. This is a `categorical` attribute.\n",
    "* age: double, values ranging from 0.1667 to 80.\n",
    "* sibsp: integers, values from 0 to 8. This is a `categorical` attribute.\n",
    "* parch: integers, values from 0 to 9. This is a `categorical` attribute.\n",
    "* ticket: string (ticket number and name)\n",
    "* fare: float, values rangins from 0 to 512.3292.\n",
    "* cabin: string. This is a `categorical` attribute.\n",
    "* embarked: char, values ins {C, Q, S}. This is a `categorical` attribute.\n",
    "* boat: string (boat letter and number). This is a `categorical` attribute.\n",
    "* body: integers: values from 1 to 328.\n",
    "* home.dest: string. This is a `categorical` attribute.\n",
    "\n",
    "_there are maybe still more `categorical` attributes._\n",
    "### TODO: transform categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical attribute values\n",
    "print(df.columns)\n",
    "for cat_col in (\"pclass\",\"survived\",\"sex\",\"sibsp\",\"parch\",\"embarked\", \"boat\", \"cabin\",):\n",
    "    print(cat_col,\":\",pd.unique(df[cat_col]))\n",
    "    print(len(pd.unique(df[cat_col])),\" distinct values\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2\n",
    "Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(x, y, title, abscissa, figsize=(20,10)):\n",
    "    \"\"\"\n",
    "    This functions plots a histogram adding the values on top of the bins.\n",
    "\n",
    "    x: values of the attribute that is being counted\n",
    "    y: counts of the x values\n",
    "    title: title to give to the histogram\n",
    "    abscissa: absissa to be displayed (what is being counted)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    width = 0.5 # the width of the bars\n",
    "    ind = np.arange(len(y))  # the x locations for the groups\n",
    "    ax.bar(ind, y, width, color=\"red\")\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(x, minor=False)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel(abscissa)\n",
    "    for i, v in enumerate(y):\n",
    "        ax.text(i-width/6, v + 10, str(v), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_null(x, y, attribute):\n",
    "    \"\"\"\n",
    "    This functions looks in the DataFrame is the `attribute` has some nan values and if so\n",
    "    appends the counts to y and adds the 'Unknown' string to x.\n",
    "    \n",
    "    x: values of the attribute (that are being counted in the original DataFrame)\n",
    "    y: counts of the values\n",
    "    \"\"\"\n",
    "    tmp = df[attribute].isnull().value_counts()\n",
    "    if len(tmp) == 2:\n",
    "        x.append('Unknown')\n",
    "        y.append(tmp[True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Plot for the travel class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_x = list(df['pclass'].value_counts().sort_index().index)\n",
    "pclass_y = list(df['pclass'].value_counts().sort_index().values)\n",
    "handle_null(pclass_x, pclass_y, 'pclass')\n",
    "\n",
    "plot_histogram(pclass_x, pclass_y, 'Histogram on the travel class', 'Travel Class', figsize=(7,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for the embarkation port:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_x = list(df['embarked'].value_counts().sort_index().index)\n",
    "embarked_y = list(df['embarked'].value_counts().sort_index().values)\n",
    "handle_null(embarked_x, embarked_y, 'embarked')\n",
    "\n",
    "for n,i in enumerate(embarked_x):\n",
    "    if i == 'S':\n",
    "        embarked_x[n] = 'Southampton'\n",
    "    if i == 'Q':\n",
    "        embarked_x[n] = 'Queenstown'\n",
    "    if i == 'C':\n",
    "        embarked_x[n] = 'Cherbourg'\n",
    "\n",
    "plot_histogram(embarked_x, embarked_y, 'Histogram of the embarkation ports', 'Embarkation Port', figsize=(7,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for the gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_x = list(df['sex'].value_counts().sort_index().index)\n",
    "sex_y = list(df['sex'].value_counts().sort_index().values)\n",
    "handle_null(sex_x, sex_y, 'sex')\n",
    "\n",
    "plot_histogram(sex_x, sex_y, 'Histogram of gender repartition of passengers', 'Gender', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for the age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_x = [u'0..9', u'10..19', u'20..29',u'30..39', u'40..49', u'50..59', u'60..69', u'70..79', u'80..89', u'Unknown']\n",
    "age_y = [0 for i in range(10)]\n",
    "for i in df['age'].index:\n",
    "    if pd.isnull(df['age'][i]):\n",
    "        age_y[9] += 1\n",
    "    else:\n",
    "        age_y[int(df['age'][i])//10] += 1\n",
    "\n",
    "plot_histogram(age_x, age_y, 'Histogram of age repartition of passengers', 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3\n",
    "_Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "We want to go through the DataFrame in order to fill the floor_count DataFrame. The latter counts the number of passengers that have a cabin on each floor (A, B, C, D, E, F, G, T (Tank Top)) to get something like that: \n",
    "<img src='Data/1.png' style=\"width: 100px;\">\n",
    "\n",
    "There are some passengers with several cabins. In that case we have to make sure that all the passenger's cabins are on the same floor. The list `problems` is meant to tackle this issue. It shows that the passengers that have cabins on different floors have cabins of the form:\n",
    "\n",
    "['F G63', 'F G63', 'F E57', 'F E46', 'F G73', 'F E69', 'F G73']\n",
    "\n",
    "We decide to ignore the cabin designation `F` as it seems to refer only to a floor and not really to a cabin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [] # this will contain the entries that have cabins on different floors.\n",
    "floor_count = pd.DataFrame([0, 0, 0, 0, 0, 0, 0, 0, 0], columns=['count'], index=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'Unknown'])\n",
    "\n",
    "for i in df.index: #let's go through the dataframe looking at the cabin of each passenger\n",
    "    cabin = df.loc[i, 'cabin']\n",
    "    \n",
    "    if pd.isnull(cabin):\n",
    "        floor_count.loc['Unknown', 'count'] += 1\n",
    "    \n",
    "    if not pd.isnull(cabin): # then we know the cabin of the passenger\n",
    "        tmp = cabin.split(' ')\n",
    "        \n",
    "        if len(tmp) == 1:\n",
    "            floor_count.loc[tmp[0][0], 'count'] += 1\n",
    "\n",
    "        if len(tmp) > 1:\n",
    "            # then the passenger has several cabins\n",
    "            # we have to check if they are all on the same floor\n",
    "            boo = True\n",
    "            for i in range(len(tmp)-1):\n",
    "                if tmp[0][0] != tmp[i+1][0]:\n",
    "                    boo = False\n",
    "                    break\n",
    "            if boo: # all cabins are on the same floor \n",
    "                floor_count.loc[tmp[0][0], 'count'] += 1\n",
    "            if not boo:\n",
    "                problems.append(cabin)\n",
    "                floor_count.loc[tmp[1][0], 'count'] += 1 # this is explained under the celle (we choose to ignore 'F')\n",
    "\n",
    "print(problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'Unknown'\n",
    "sizes = np.array(floor_count.values)\n",
    "\n",
    "def absolute_value(val):\n",
    "    a  = np.round(val/100.*sizes.sum(), 0)\n",
    "    return a\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.pie(sizes, labels=labels, autopct=absolute_value,\n",
    "        shadow=False, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Pie chart of the repartition of passengers by cabin floor (including unknowns)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'\n",
    "sizes = np.array(floor_count.values[:-1])\n",
    "\n",
    "def absolute_value(val):\n",
    "    a  = np.round(val/100.*sizes.sum(), 0)\n",
    "    return a\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.pie(sizes, labels=labels, shadow=False, autopct=absolute_value, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Pie chart of the repartition of passengers by cabin floor (excluding unknowns)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.4\n",
    "_For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "There are no NAs for the attribute `survived` so we do not have to worry about it in this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survivors_count contains for each class the number of passengers that survived and those did not. \n",
    "# NAs are excluded of the count.\n",
    "survival_count = pd.DataFrame(df['name'].groupby([df.pclass, df.survived]).count())\n",
    "survival_count.columns = ['count']\n",
    "\n",
    "# survivors_percentage contains for each class the percentage of passengers that survived or not.\n",
    "# NAs are excluded.\n",
    "survival_percentages = pd.DataFrame(df['name'].groupby(df.pclass).count())\n",
    "survival_percentages.columns = ['pclass_total']\n",
    "survival_percentages = pd.merge(survival_count, survival_percentages, left_index=True, right_index=True)\n",
    "survival_percentages['percentage'] = np.divide(survival_percentages['count'], survival_percentages['pclass_total'])\n",
    "\n",
    "survival_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'\n",
    "sizes = np.array(floor_count.values[:-1])\n",
    "\n",
    "plt.subplots(figsize=(15,4))\n",
    "\n",
    "def percent(val):\n",
    "    a  = str(val.round(2)) + \" %\"\n",
    "    return a\n",
    "\n",
    "for i in range(1,4):\n",
    "    data_pie = survival_percentages[survival_percentages.index.labels[0]==(i-1)]\n",
    "    y = data_pie['percentage'].values\n",
    "    x = 'Survived', 'Dead'\n",
    "    plt.subplot(1,3,i)\n",
    "    plt.pie(y, labels=x, autopct=percent, startangle=90)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.title('Category '+ str(i))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.5\n",
    "_Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "There are still no NAs for the attribute `survived` so we do not have to worry about it in this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data ready\n",
    "# get survivor count\n",
    "total_class_survived = pd.DataFrame(df['name'].groupby([df.pclass, df.sex, df.survived]).count())\n",
    "total_class_survived.columns = ['count']\n",
    "total_class_survived=total_class_survived.reset_index()\n",
    "\n",
    "# sum of survivors per class\n",
    "total_class = pd.DataFrame(df['name'].groupby([df.sex, df.pclass]).count())\n",
    "total_class.columns = ['pclass_sex_total']\n",
    "total_class = total_class.reset_index()\n",
    "total_class = pd.merge(total_class_survived, total_class)\n",
    "total_class = total_class.set_index(['pclass', 'survived', 'sex'])\n",
    "total_class['percentage'] = np.divide(total_class['count'], total_class['pclass_sex_total'])\n",
    "total_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can get an array of 4\\*3 containing the percentages for survived / dead women and men, respectively.\n",
    "\n",
    "`survived_dead[0][i]` contains the percentage of women of class i who died\n",
    "\n",
    "`survived_dead[1][i]` contains the percentage of women of class i who survived\n",
    "\n",
    "`survived_dead[2][i]` contains the percentage of men of class i who died\n",
    "\n",
    "`survived_dead[3][i]` contains the percentage of men of class i who survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_dead = [] #4*3 array\n",
    "for sex in range(0,2):\n",
    "    for survived in range(0,2):\n",
    "        tmp = total_class[total_class.index.labels[2] == sex] # filter by survived \n",
    "        tmp = tmp[tmp.index.labels[1] == survived] # filter by sex\n",
    "        survived_dead.append(tmp['percentage'].values)\n",
    "\n",
    "survived_dead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot histogram\n",
    "We want to plot a hitogram grouped by pclass, always showing survived / dead for m / f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
    "\n",
    "# box positions\n",
    "N = 3\n",
    "ind = np.arange(N) # x locations for the groups\n",
    "width = .2 # the width of the bars\n",
    "\n",
    "dx=ind\n",
    "rects=[] # dead_women, living_women, dead_men, living_men\n",
    "\n",
    "color_map = [colors['forestgreen'], colors['lightgreen'], colors['orangered'], colors['coral']]\n",
    "\n",
    "for e in range(1,5):\n",
    "    rects.append(ax.bar(dx, survived_dead[e-1], width,color=color_map[e-1]))\n",
    "    dx=ind+(e)*width\n",
    "\n",
    "    # TODO add labels\n",
    "    \n",
    "# bars\n",
    "fsize=15\n",
    "# axes and labels\n",
    "ax.set_xlim(-width,len(ind)+width)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlabel('Travel Class', fontsize=fsize)\n",
    "ax.set_ylabel('Percentage Survivors [%]', fontsize=fsize)\n",
    "ax.set_title('Survivors by travel class and gender', fontsize=fsize)\n",
    "xTickMarks = [str(i) for i in range(1,4)]\n",
    "ax.set_xticks(ind + width)\n",
    "xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "plt.setp(xtickNames, rotation=45, fontsize=fsize)\n",
    "\n",
    "\n",
    "## add a legend\n",
    "ax.legend(('Women Dead', 'Women Alive','Men Dead', 'Men Alive'), fontsize=fsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.6 \n",
    "_Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two labels, based on age\n",
    "df_sorted = df[df.age.notnull()].sort_values(by='age')\n",
    "# TODO convert decimals\n",
    "df_sorted['cat'] = pd.cut(df_sorted['age'].values, 2, labels=['young', 'old'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data ready\n",
    "# get survivor count\n",
    "total_class_survived = pd.DataFrame(df_sorted[['cat']].groupby([df_sorted.pclass, df_sorted.sex, \n",
    "                                                                df_sorted.survived, df_sorted.cat]).count())\n",
    "total_class_survived.columns = (['count'])\n",
    "total_class_survived = total_class_survived.reset_index()\n",
    "\n",
    "# sum of survivors per class to get the percentage\n",
    "total_class = pd.DataFrame(df_sorted['cat'].groupby([df_sorted.sex, df_sorted.pclass, df_sorted.cat]).count())\n",
    "total_class.columns = ['countTOT'] # total count\n",
    "total_class = total_class.reset_index()\n",
    "total_class = pd.merge(total_class_survived, total_class)\n",
    "total_class = total_class.set_index(['cat', 'pclass', 'sex', 'survived'])\n",
    "total_class['Percentage'] = np.divide(total_class['count'], total_class['countTOT']).round(2)\n",
    "total_class = total_class.reset_index()\n",
    "total_class = total_class.drop('countTOT', axis=1)\n",
    "total_class.columns = ['Age Category', 'Travel Class', 'Sex', 'Survived', 'Count', 'Percentage']\n",
    "total_class = total_class.set_index(['Age Category', 'Travel Class', 'Sex', 'Survived'])\n",
    "total_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
