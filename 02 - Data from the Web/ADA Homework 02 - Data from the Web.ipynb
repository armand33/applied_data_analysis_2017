{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data from the Web\n",
    "\n",
    "## Assignment\n",
    "1. Obtain the 200 top-ranking universities in www.topuniversities.com ([ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018)). In particular, extract the following fields for each university: name, rank, country and region, number of faculty members (international and total) and number of students (international and total). Some information is not available in the main list and you have to find them in the [details page](https://www.topuniversities.com/universities/ecole-polytechnique-fédérale-de-lausanne-epfl).\n",
    "Store the resulting dataset in a pandas DataFrame and answer the following questions:\n",
    "    - Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?\n",
    "    - Answer the previous question aggregating the data by (c) country and (d) region.\n",
    "\n",
    "Plot your data using bar charts and describe briefly what you observed.\n",
    "\n",
    "2. Obtain the 200 top-ranking universities in www.timeshighereducation.com ([ranking 2018](http://timeshighereducation.com/world-university-rankings/2018/world-ranking)). Repeat the analysis of the previous point and discuss briefly what you observed.\n",
    "\n",
    "3. Merge the two DataFrames created in questions 1 and 2 using university names. Match universities' names as well as you can, and explain your strategy. Keep track of the original position in both rankings.\n",
    "\n",
    "4. Find useful insights in the data by performing an exploratory analysis. Can you find a strong correlation between any pair of variables in the dataset you just created? Example: when a university is strong in its international dimension, can you observe a consistency both for students and faculty members?\n",
    "\n",
    "5. Can you find the best university taking in consideration both rankings? Explain your approach.\n",
    "\n",
    "Hints:\n",
    "- Keep your Notebook clean and don't print the verbose output of the requests if this does not add useful information for the reader.\n",
    "- In case of tie, use the order defined in the webpage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "* Comment the functions defined at the beginning\n",
    "* Manually add the missing values by looking at the websites of the universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools for scraping\n",
    "\n",
    "* `load_data` is a function that gets the json file from the main page containing the ranking at returns the extracted pandas DataFrame\n",
    "\n",
    "* `plot_histogram` is a utility function to plot histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(URL):\n",
    "    # make a request\n",
    "    r = requests.get(URL)\n",
    "    r = r.json()\n",
    "    # convert the data to pandas DataFrame\n",
    "    df = pd.DataFrame(r['data'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Scraping www.topuniversities.com\n",
    "\n",
    "This website is build in a specific way. We cannot have access to what we call details (faculty members (total and international) and students (total and international)) directly on the ranking page. \n",
    "\n",
    "To get those details we have to scrap directly the page of the site corresponding to the university. To do so we will use the function `scrape_details`. It parses a HTML file using Beautiful Soup and then extracts the required data.\n",
    "\n",
    "All soup commands are executed between try/except in order to be able to trace the missing data. If there is a missing data, then `AttributeError` is raised and we can print a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_details(raw_file, i, df) :\n",
    "    \"\"\"\n",
    "    Arguments:  - raw html file returned by a GET call\n",
    "                - i and df are there to be able to print a useful message about the missing data \n",
    "                (i is the index in df of the current university)\n",
    "    Return: detail values in the form of a dictionnary\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(raw_file.text,\"html.parser\")\n",
    "    \n",
    "    try:\n",
    "        # getting the data on the site using Beautiful Soup\n",
    "        total_faculty = soup.find('div',class_='total faculty').find('div',class_='number').text\n",
    "        # extracting the values and casting them to integers\n",
    "        tot_fac = int(total_faculty[1:-1].replace(',',''))\n",
    "    except AttributeError:\n",
    "        print('Total faculty members unavailable for ' + df.loc[i, 'name'])\n",
    "        tot_fac = 0\n",
    "        \n",
    "    try:\n",
    "        # getting the data on the site using Beautiful Soup\n",
    "        total_student = soup.find('div',class_='total student').find('div',class_='number').text\n",
    "        # extracting the values and casting them to integers\n",
    "        tot_stu = int(total_student[1:-1].replace(',',''))\n",
    "    except AttributeError:\n",
    "        print('Total students unavailable for ' + df.loc[i, 'name'])\n",
    "        tot_stu = 0\n",
    "\n",
    "    try:\n",
    "        # getting the data on the site using Beautiful Soup\n",
    "        inter_faculty = soup.find('div',class_='inter faculty').find('div',class_='number').text\n",
    "        # extracting the values and casting them to integers\n",
    "        int_fac = int(inter_faculty[1:-1].replace(',',''))\n",
    "    except AttributeError:\n",
    "        print('International faculty members unavailable for ' + df.loc[i, 'name'])\n",
    "        int_fac = 0\n",
    "\n",
    "    try:\n",
    "        # getting the data on the site using Beautiful Soup\n",
    "        inter_student = soup.find('div',class_='total inter').find('div',class_='number').text\n",
    "        # extracting the values and casting them to integers\n",
    "        int_stu = int(inter_student[1:-1].replace(',',''))\n",
    "    except AttributeError:\n",
    "        print('International students unavailable for ' + df.loc[i, 'name'])\n",
    "        int_stu = 0\n",
    "    \n",
    "        \n",
    "    return {'total_faculty_members' : tot_fac, 'total_students' : tot_stu, \n",
    "            'international_faculty_members' : int_fac, 'international_students' : int_stu}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting ranking on main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_topuni = 'https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt?_=1508105606999'\n",
    "\n",
    "# load the ranking\n",
    "df_topuni = load_data(url_topuni)\n",
    "\n",
    "# Select the interresting columns\n",
    "df_topuni = df_topuni[['title','rank_display','region','country','url']]\n",
    "\n",
    "# Rename the columns\n",
    "df_topuni.columns = ['name','rank', 'region','country','url']\n",
    "\n",
    "# Cleaning the rank attribute\n",
    "df_topuni['rank'] = df_topuni['rank'].str.replace('=', '')\n",
    "\n",
    "# keeping only the first 200 universities of the ranking\n",
    "df_topuni = df_topuni.loc[:199]\n",
    "\n",
    "# converting rank type to integer\n",
    "df_topuni['rank'] = df_topuni['rank'].astype(int)\n",
    "\n",
    "df_topuni.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting details for each university\n",
    "\n",
    "To get details (faculty members (total and international), students (total and international)) we have to make a `GET` request on the page of each faculty (following the url collected if the dataframe). There we use the function scrape details that parses the HTML result of the `GET` request and extracts the appropriate fields.\n",
    "\n",
    "The results for each university are stored in a dictionnary and `details` is a list of those dictionnaries.\n",
    "\n",
    "If the required data is not available on the page, a message is printed and values are set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.topuniversities.com\"\n",
    "details = [] # this is a list of dictionnaries containing the details\n",
    "\n",
    "for i in tqdm_notebook(range(200)):\n",
    "    # for each university we scrap the university page\n",
    "    details.append(scrape_details(requests.get(url+df_topuni.url[i]), i, df_topuni))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB\n",
    "The result of the previous cell is not displayed properly on Github as it required the execution of the JavaScript widget. The function `tqdm_notebook` is used to show a progress bar of the scrapping of details. The file imgs/1.png is a screenshot of what it looks like in Chrome.\n",
    "\n",
    "<img src=\"imgs/1.png\", width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting details to a pandas DataFrame\n",
    "details = pd.DataFrame(details)\n",
    "\n",
    "# we no longer need the url field because we scrapped the details\n",
    "df_topuni = df_topuni.drop('url', axis = 1)\n",
    "\n",
    "# concatenating details to core data\n",
    "df_topuni = pd.concat([df_topuni,details],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check for unique index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topuni.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding derived columns (ratio students per faculty member and ratio of international students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topuni['ratio_students_per_faculty_member'] = df_topuni['total_students']/df_topuni['total_faculty_members']\n",
    "df_topuni['ratio_international_students'] = df_topuni['international_students']/df_topuni['total_students']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topuni.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the matching between countries and regions (necessary for next scraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = {}\n",
    "for i in range(len(df_topuni)):\n",
    "    c = df_topuni.loc[i, 'country']\n",
    "    if c not in regions.keys():\n",
    "        regions[c] = df_topuni.loc[i, 'region']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Scraping www.timeshighereducation.com\n",
    "Assumptions\n",
    "- We are using [this site](https://www.timeshighereducation.com/world-university-rankings/2018/world-ranking#!/page/0/length/-1/sort_by/rank/sort_order/asc/cols/stats) which contains the rankings of 2018.\n",
    "- Rank saved within `<td class=\"rank ...\"><td>` element\n",
    "- University saved within `<a href=\"...\" class=\"ranking-institution-title ...\"></a>` element\n",
    "- Country saved within `<div class=\"location\"></div>` element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the data returned in the json file returned in the `GET` request are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_times = 'https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'\n",
    "\n",
    "# load the ranking\n",
    "df_times = load_data(url_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need all columns, thus we extract only the ones relevant to the data we are looking for: _name, rank, country and region, number of faculty members (international and total) and number of students (international and total)._\n",
    "\n",
    "These columns are derived as follows:\n",
    "- `name`: column `name`\n",
    "- `country`: `location`\n",
    "- `region`: in detail URL?\n",
    "- `number of faculty members (international)`: ?\n",
    "- `number of faculty members (total)`: `stats_number_students` times `stats_student_staff_ratio`\n",
    "- `number of students (international)`: `stats_number_students` times `stats_pc_intl_students`\n",
    "- `number of students (total)`: `stats_number_students`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the interesting columns\n",
    "df_times = df_times[['name', 'rank', 'location', 'stats_number_students', 'stats_student_staff_ratio',\n",
    "                     'stats_pc_intl_students']]\n",
    "\n",
    "# rename the columns\n",
    "df_times.columns = ['name', 'rank', 'country', 'total_students', 'ratio_students_per_faculty_member', \n",
    "                    'ratio_international_students']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to do some data cleanup:\n",
    "- remove equal sign (`=`) in field `rank` (Universities having the same rank) and removing universities having a rank above 200\n",
    "-  convert percentage of students in field `stats_pc_intl_students` (e.g. 83%) to float (e.g., 0.83) for multiplication\n",
    "- Remove commas and cast to  type `int` for column `stats_number_students` (\"number of students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the rank attribute\n",
    "df_times['rank'] = df_times['rank'].str.replace('=', '')\n",
    "df_times = df_times[np.isin(df_times['rank'], ['1001+', '201–250', '251–300', '301–350', '351–400', '401–500', '501–600', '601–800', '801–1000'],\n",
    "                invert=True)]\n",
    "df_times['rank'] = df_times['rank'].astype(int)\n",
    "\n",
    "# Convert percentage (e.g. 83%) to float (e.g., 0.83) for multiplication\n",
    "def divide(x, n = 100):\n",
    "    return float(x)/n\n",
    "\n",
    "df_times['ratio_international_students'] = df_times['ratio_international_students'].str.replace('%', '').apply(divide, n=100)\n",
    "\n",
    "df_times['ratio_students_per_faculty_member'] = df_times['ratio_students_per_faculty_member'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Cleaning the number of students attribute\n",
    "df_times['total_students'] = df_times['total_students'].str.replace(',', '').astype(int)\n",
    "df_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now derive new columns for the missing data fields based on the existing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derived columns\n",
    "df_times['total_faculty_members'] = np.round(df_times['total_students'] / (df_times['ratio_students_per_faculty_member'])).astype(int)\n",
    "df_times['international_students'] = np.round(df_times['total_students'] * df_times['ratio_international_students']).astype(int)\n",
    "display(df_times.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the attribute region based on the data we got from scraping 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_times)):\n",
    "    try:\n",
    "        df_times.loc[i, 'region'] = regions[df_times.loc[i, 'country']]\n",
    "    except KeyError:\n",
    "        print('Do not know the region for ' + df_times.loc[i, 'country'] + ' ' + str(i)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add the missing entries by hand.\n",
    "Topuniversities has no university from Luxembourg in top 200 and uses Russia instead of Russian Federation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times.loc[178, 'region'] = 'Europe'\n",
    "df_times.loc[193, 'region'] = 'Europe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "We can now answer the following questions:\n",
    "- Which are the best universities in term of: \n",
    "    * (a) ratio between faculty members and students\n",
    "    * (b) ratio of international students\n",
    "- Answer the previous question aggregating the data by \n",
    "    * (c) country\n",
    "    * (d) region\n",
    "    \n",
    "We answer these following questions by ploting the computed rankings. We plot the results for Times and Topuniversities next to each other to make it easier to compare the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(df1, df2, x, y, title, xlab, figsize=(20,10)):\n",
    "    \"\"\"\n",
    "    This functions plots two histograms next to each other (df1 and df2)\n",
    "    adding the values on top of the bins.\n",
    "    \n",
    "    df1: dataframe 1\n",
    "    df2: dataframe 2\n",
    "    x: column name for x axis\n",
    "    y: column name for y axis\n",
    "    title: title to give to the histogram\n",
    "    xlab: xlabel\n",
    "    \"\"\"\n",
    "    lx = []\n",
    "    lx.append(df1[x].values)\n",
    "    lx.append(df2[x].values)\n",
    "    ly = []\n",
    "    ly.append(np.round(df1[y],2))\n",
    "    ly.append(np.round(df2[y],2))\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
    "    width = 0.5 # the width of the bars\n",
    "    ind = []\n",
    "    ind.append(np.arange(len(ly[0])))  # the x locations for the groups\n",
    "    ind.append(np.arange(len(ly[1])))\n",
    "    \n",
    "    for k in range(2):\n",
    "        ax[k].bar(ind[k], ly[k], width, color=\"red\")\n",
    "        ax[k].set_xticks(ind[k])\n",
    "        ax[k].set_xticklabels(lx[k], rotation=90, fontsize=13)\n",
    "        for i, v in enumerate(ly[k]):\n",
    "\n",
    "            ax[k].text(i-width/2, v*1.02, str(v), color='red', fontsize = 15)\n",
    "    \n",
    "    ax[0].set_title('Topuniversities ranking', fontsize=15)\n",
    "    ax[1].set_title('Times ranking', fontsize=15)\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking in term of ratio between students and faculty members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp_topuni = df_topuni.sort_values(by=['ratio_students_per_faculty_member']).head(10)\n",
    "tmp_times = df_times.sort_values(by=['ratio_students_per_faculty_member']).head(10)\n",
    "\n",
    "plot_histogram(tmp_topuni, tmp_times, 'name', 'ratio_students_per_faculty_member', \n",
    "               title='Ratio students per faculty member', xlab='University', figsize=(7,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking in term of ratio of international students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of international students\n",
    "tmp_topuni = df_topuni.sort_values(by=['ratio_international_students'], ascending=False).head(10)\n",
    "tmp_times = df_times.sort_values(ascending=False,by=['ratio_international_students']).head(10)\n",
    "\n",
    "plot_histogram(tmp_topuni, tmp_times, 'name', 'ratio_international_students', \n",
    "               title='International Students Percentage', xlab='University', figsize=(7,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated by country\n",
    "Now, let's plot the same results aggregated by country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking of countries in term of ratio of students to staff in their universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_topuni = df_topuni.groupby('country').mean().sort_values(by=['ratio_students_per_faculty_member']).head(10)\n",
    "tmp_times = df_times.groupby('country').mean().sort_values(by=['ratio_students_per_faculty_member']).head(10)\n",
    "\n",
    "tmp_topuni.reset_index(inplace=True)\n",
    "tmp_times.reset_index(inplace=True)\n",
    "\n",
    "plot_histogram(tmp_topuni, tmp_times,'country', 'ratio_students_per_faculty_member', \n",
    "               title='Ratio students per faculty member', xlab='Country', figsize=(7,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking of countries in term of international students percentage in their universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_topuni = df_topuni.groupby('country').mean().sort_values(ascending=False,\n",
    "                                                             by=['ratio_international_students']).head(10)\n",
    "tmp_times = df_times.groupby('country').mean().sort_values(ascending=False,\n",
    "                                                           by=['ratio_international_students']).head(10)\n",
    "\n",
    "tmp_topuni.reset_index(inplace=True)\n",
    "tmp_times.reset_index(inplace=True)\n",
    "\n",
    "plot_histogram(tmp_topuni, tmp_times,'country', 'ratio_international_students', \n",
    "               title='International Students Percentage', xlab='Country', figsize=(7,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated by region\n",
    "Now, let's plot the same results aggregated by region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking of regions in term of ratio of international students in their universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_topuni = df_topuni.groupby('region').mean().sort_values(by=['ratio_students_per_faculty_member']).head(10)\n",
    "tmp_topuni.reset_index(inplace=True)\n",
    "\n",
    "tmp_times = df_times.groupby('region').mean().sort_values(by=['ratio_students_per_faculty_member']).head(10)\n",
    "tmp_times.reset_index(inplace=True)\n",
    "\n",
    "plot_histogram(tmp_topuni, tmp_times,'region', 'ratio_students_per_faculty_member', title='Ratio students per faculty member',\n",
    "               xlab='region', figsize=(7,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking of regions in term of ratio of students to staff in their universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_topuni = df_topuni.groupby('region').mean().sort_values(ascending=False,by=['ratio_international_students']).head(10)\n",
    "tmp_topuni.reset_index(inplace=True)\n",
    "\n",
    "tmp_times = df_times.groupby('region').mean().sort_values(ascending=False,by=['ratio_international_students']).head(10)\n",
    "tmp_times.reset_index(inplace=True)\n",
    "\n",
    "plot_histogram(tmp_topuni, tmp_times,'region', 'ratio_international_students', title='International Students Percentage',\n",
    "               xlab='Region', figsize=(7,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we get the total number of distinct University names in both datasets. These are not matched yet, so there may be duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_topuni = set(df_topuni.loc[:, 'name'])\n",
    "names_times = set(df_times.loc[:, 'name'])\n",
    "names = names_times.union(names_topuni)\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking for universities that have different names in the two rankings but are the same\n",
    "\n",
    "To do that we use a library calle fuzzywuzzy. It uses the Levenshtein distance that is meant to measure how two strings are close to each other to compute a matching score between two strings.\n",
    "A score of 100 means the two strings are the same and for example:\n",
    "\n",
    "$ score($'The University of Exeter', 'University of Exeter'$) = 95$\n",
    "\n",
    "For each university name in the TopUniversities ranking, we look for the university that has the highest matching score in the Times ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = {}\n",
    "for name in names_topuni:\n",
    "    test = process.extractOne(name, names_times)\n",
    "    if test[0] != name and test[1] > 90:\n",
    "        n[test[0]] = name\n",
    "        print(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the list, we see the only mismatch is with the University of Bergen that we remove from the dictionnary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del n['University of Bern']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find a couple of more matchings by setting the level of match at 80 rather than 90 but in this case there are a lot of mismatch. The matches are added by hand to the dictionnary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n['University of Tübingen'] = 'Eberhard Karls Universität Tübingen'\n",
    "n['Free University of Berlin'] = 'Freie Universitaet Berlin'\n",
    "n['Humboldt University of Berlin'] = 'Humboldt-Universität zu Berlin'\n",
    "n['Wageningen University & Research'] = 'Wageningen University'\n",
    "n['University of Montreal'] = 'Université de Montréal'\n",
    "n['Trinity College Dublin'] = 'Trinity College Dublin, The University of Dublin'\n",
    "n['Heidelberg University'] = 'Ruprecht-Karls-Universität Heidelberg'\n",
    "n['Scuola Superiore Sant’Anna'] = \"Scuola Superiore Sant'Anna Pisa di Studi Universitari e di Perfezionamento\"\n",
    "n['The University of New South Wales (UNSW Sydney)'] = 'University of New South Wales'\n",
    "n['University of Freiburg'] = 'Albert-Ludwigs-Universitaet Freiburg'\n",
    "n['Autonomous University of Barcelona'] =  'Universitat Autònoma de Barcelona'\n",
    "n['Technical University of Berlin'] = 'Technische Universität Berlin (TU Berlin)'\n",
    "n['Pierre and Marie Curie University'] = 'Université Pierre et Marie Curie (UPMC)'\n",
    "n['University of New South Wales'] = 'The University of New South Wales (UNSW Sydney)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now, for the matchings found, change the university names in the Times ranking to have the same as in the TopUniversities ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_times)):\n",
    "    tmp = df_times.loc[i, 'name']\n",
    "    if tmp in n.keys():\n",
    "        df_times.loc[i, 'name'] = n[tmp]\n",
    "        \n",
    "names_topuni = set(df_topuni.loc[:, 'name'])\n",
    "names_times = set(df_times.loc[:, 'name'])\n",
    "names = names_times.union(names_topuni)\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = names_times.intersection(names_topuni)\n",
    "len(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topuni.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times.columns = ['name', 'times_rank', 'country', 'times_total_students','times_ratio_students_per_faculty_member',\n",
    "                    'times_ratio_international_students', 'times_total_faculty_member',\n",
    "                    'times_international_students', 'region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topuni.columns = ['name', 'topuni_rank', 'region', 'country', 'topuni_international_faculty_members',\n",
    "       'topuni_international_students', 'topuni_total_faculty_members', 'topuni_total_students',\n",
    "       'topuni_ratio_students_per_faculty_member', 'topuni_ratio_international_students']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universities appearing in both rankings: Correlations\n",
    "In the further analysis below, we chose to keep only Universities contained in both rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_times.merge(df_topuni, on='name', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if df.loc[i, 'country_y'] != df.loc[i, 'country_x']:\n",
    "        print(i, df.loc[i, 'country_y'], df.loc[i, 'country_x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only mismatch is between Russia and the Russian Federation and that is not a real mismatch. We can then drop a column of countries.\n",
    "There cannot be any mismatch between regions as we extracted the regions from the top_uni dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['name', 'times_rank', 'topuni_rank', 'country_x', 'region_x', 'times_total_students', 'topuni_total_students',\n",
    "         'times_ratio_students_per_faculty_member', 'topuni_ratio_students_per_faculty_member',\n",
    "         'times_ratio_international_students', 'topuni_ratio_international_students',\n",
    "         'times_total_faculty_member', 'topuni_total_faculty_members', \n",
    "         'times_international_students', 'topuni_international_students','topuni_international_faculty_members']]\n",
    "df.columns = ['name', 'times_rank', 'topuni_rank', 'country', 'region', 'times_total_students', \n",
    "              'topuni_total_students',\n",
    "              'times_ratio_students_per_faculty_member', 'topuni_ratio_students_per_faculty_member',\n",
    "              'times_ratio_international_students', 'topuni_ratio_international_students',\n",
    "              'times_total_faculty_member', 'topuni_total_faculty_members', \n",
    "              'times_international_students', 'topuni_international_students','topuni_international_faculty_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universities appearing only in one ranking\n",
    "For record, we also display the Universities which appear only in one of both rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topuni_r=pd.DataFrame(df_topuni[(~df_topuni[\"name\"].isin(df[\"name\"]))])\n",
    "df_times_r=pd.DataFrame(df_times[(~df_times[\"name\"].isin(df[\"name\"]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df_topuni_r.head(2))\n",
    "display(df_times_r.head(2))\n",
    "print(str(len(df)) + \" common rankings in total\")\n",
    "print(str(len(df_times_r))+ \" Universities of the time ranking not contained in the Topuni ranking\")\n",
    "print(str(len(df_topuni_r))+ \" Universities of the topuni ranking not contained in the Times ranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "The result below allows to visualize correlations between each variable. First, we visualize variable correlations for each website individually\n",
    "#### Topuniversities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(df, mask_diag=True, f_size=(6,5)):\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=f_size)\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    if mask_diag:\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    sns.heatmap(corr, mask=mask, cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "                square=True, ax=ax, annot=True)\n",
    "    plt.show()\n",
    "    \n",
    "get_corr_matrix(df_topuni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "#### Rank\n",
    "- The rank of the University correlates most positively (`0.37`) with the ratio students to factulty members. In fact, the correlation direction here has to be read differently, because a higher rating means a \"lower number\", therefore this correlation is negative. The more students with respect to faculty member the University has, the less people there are.\n",
    "- The rank of the University correlates has the strongest negative correlation (`-0.53`) with international faculty members and international students, respectively (`-0.37`). Again, this correlation is actually positive because high rank means low rank number.\n",
    "\n",
    "#### Other variables\n",
    "- There is a strong positive correlation between international faculty members and international students (`0.65`).\n",
    "- Similarly the number of faculty members strongly correlates with the number of students (`0.77`), representing simply big or small universities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Times Higher Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " get_corr_matrix(df_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar tendencies as above can be seen. To visualize the differences more closely, let's show the correlogram of the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr_matrix(df,mask_diag=False,f_size=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "#### Rank (first and second column, or row, respectively)\n",
    "The correlation of the ranking with international faculty members and students is strong with both datsets, although it is stronger (`-0.51`) for ther topuni dataset, for which the international faculty member information was sourced. Interestingly, this shows that taking into account the criterion of international faculty members influences the topuniversities ranking.\n",
    "#### Other comments\n",
    "The correlation between the variables of both ranking websites is generally quite strong, as the red 2\\*2-rectangles along the diagonal of the matrix suggest. The correlation is least strong for the `ratio_students_by_faculty_member` and `total_faculty_members` which might have been calculated using different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best University taking into account both approaches\n",
    "Following aggregation schemes can be taken into account\n",
    "- Mean between rankings: this seems most straight-forward, as it considers both rankings of equal trustworthiness and assumes they can be weighted without any preprocessing.\n",
    "- Weighted ranking taking into account other variables such as international students percentage.\n",
    "- Weigthed mean over all categories, excluding the ranking\n",
    "- Trying to decorrelate variables that are only present in one dataset?\n",
    "\n",
    "### Mean between rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rank_mean\"]=(df[\"times_rank\"]+df[\"topuni_rank\"])/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this method, the top 10 universities are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"name\",\"rank_mean\"]].sort_values(by=\"rank_mean\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted ranking taking into account other variables such as international students percentage.\n",
    "We can also rank universities according to the mean of their percentage of international students in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mean_ratio_international_students\"]=(df[\"times_ratio_international_students\"]+df[\"topuni_ratio_international_students\"])/2\n",
    "df[[\"name\",\"mean_ratio_international_students\"]].sort_values(by=\"mean_ratio_international_students\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the right ETH on top!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test country map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "#ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "#ax.add_feature(cartopy.feature.COASTLINE)\n",
    "#ax.add_feature(cartopy.feature.BORDERS, linestyle='-', alpha=.5)\n",
    "#ax.add_feature(cartopy.feature.LAKES, alpha=0.95)\n",
    "#ax.add_feature(cartopy.feature.RIVERS)\n",
    "ax.set_extent([-150, 60, -25, 60])\n",
    "\n",
    "shpfilename = shpreader.natural_earth(resolution='110m',\n",
    "                                      category='cultural',\n",
    "                                      name='admin_0_countries')\n",
    "reader = shpreader.Reader(shpfilename)\n",
    "countries = reader.records()\n",
    "\n",
    "for country in countries:\n",
    "    if country.attributes['adm0_a3'] == 'USA':\n",
    "        ax.add_geometries(country.geometry, ccrs.PlateCarree(),\n",
    "                          facecolor=(0, 0, 1),\n",
    "                          label=country.attributes['adm0_a3'])\n",
    "    else:\n",
    "        ax.add_geometries(country.geometry, ccrs.PlateCarree(),\n",
    "                          facecolor=(0, 1, 0),\n",
    "                          label=country.attributes['adm0_a3'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1128fbeb8>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "\n",
    "\n",
    "m = folium.Map(location=[45.5236, -122.6750])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
