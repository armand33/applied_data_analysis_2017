{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "import networkx as nx\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from networkx.algorithms import bipartite\n",
    "from matplotlib.pyplot import cm\n",
    "from operator import itemgetter\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Propensity score matching\n",
    "\n",
    "In this exercise, you will apply [propensity score matching](http://www.stewartschultz.com/statistics/books/Design%20of%20observational%20studies.pdf), which we discussed in lecture 5 (\"Observational studies\"), in order to draw conclusions from an observational study.\n",
    "\n",
    "We will work with a by-now classic dataset from Robert LaLonde's study \"[Evaluating the Econometric Evaluations of Training Programs](http://people.hbs.edu/nashraf/LaLonde_1986.pdf)\" (1986).\n",
    "The study investigated the effect of a job training program (\"National Supported Work Demonstration\") on the real earnings of an individual, a couple of years after completion of the program.\n",
    "Your task is to determine the effectiveness of the \"treatment\" represented by the job training program.\n",
    "\n",
    "#### Dataset description\n",
    "\n",
    "- `treat`: 1 if the subject participated in the job training program, 0 otherwise\n",
    "- `age`: the subject's age\n",
    "- `educ`: years of education\n",
    "- `race`: categorical variable with three possible values: Black, Hispanic, or White\n",
    "- `married`: 1 if the subject was married at the time of the training program, 0 otherwise\n",
    "- `nodegree`: 1 if the subject has earned no school degree, 0 otherwise\n",
    "- `re74`: real earnings in 1974 (pre-treatment)\n",
    "- `re75`: real earnings in 1975 (pre-treatment)\n",
    "- `re78`: real earnings in 1978 (outcome)\n",
    "\n",
    "If you want to brush up your knowledge on propensity scores and observational studies, we highly recommend Rosenbaum's excellent book on the [\"Design of Observational Studies\"](http://www.stewartschultz.com/statistics/books/Design%20of%20observational%20studies.pdf). Even just reading the first chapter (18 pages) will help you a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lalonde.csv').set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a categorical feature for the race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = 'white'\n",
    "df.loc[df['black'] == 1, 'race'] = 'black'\n",
    "df.loc[df['hispan'] == 1, 'race'] = 'hispanic'\n",
    "df['race'] = df['race'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A naive analysis\n",
    "\n",
    "_Compare the distribution of the outcome variable (`re78`) between the two groups, using plots and numbers.\n",
    "To summarize and compare the distributions, you may use the techniques we discussed in lectures 4 (\"Read the stats carefully\") and 6 (\"Data visualization\")._\n",
    "\n",
    "_What might a naive \"researcher\" conclude from this superficial analysis?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Treated group : {} individuals'.format(len(df.loc[df.treat == 1])))\n",
    "print('Control group : {} individuals'.format(len(df.loc[df.treat == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Treated group mean earnings in 1974 : {}'.format(int(df.loc[df.treat == 1, 're74'].mean())))\n",
    "print('Control group mean earnings in 1974 : {}'.format(int(df.loc[df.treat == 0, 're74'].mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Treated group mean earnings in 1975 : {}'.format(int(df.loc[df.treat == 1, 're75'].mean())))\n",
    "print('Control group mean earnings in 1975 : {}'.format(int(df.loc[df.treat == 0, 're75'].mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Treated group mean earnings in 1978 : {}'.format(int(df.loc[df.treat == 1, 're78'].mean())))\n",
    "print('Control group mean earnings in 1978 : {}'.format(int(df.loc[df.treat == 0, 're78'].mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now also want to show the means and standard deviations of the salary of treated and non-treated people before in all years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(1,3,sharey=True)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "\n",
    "cols = ['re74','re75','re78']\n",
    "years = ['1974','1975','1978']\n",
    "\n",
    "for i in range(3): # 0 = treated (axis 0), 1 = non-treated (axis 1)\n",
    "    axes[i].boxplot([df.loc[df.treat==0, cols[i]].values, df.loc[df.treat==1, cols[i]].values],showfliers=True)\n",
    "    sns.despine(offset=15, trim=False)\n",
    "    axes[i].set_xticklabels(['Control population', 'Treated population'])\n",
    "    axes[i].set_title('Salary in ' + str(years[i]) + ' for both population groups')\n",
    "    axes[i].set_ylabel('Salary') # TODO annual?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A closer look at the data\n",
    "\n",
    "You're not naive, of course (and even if you are, you've learned certain things in ADA), so you aren't content with a superficial analysis such as the above.\n",
    "You're aware of the dangers of observational studies, so you take a closer look at the data before jumping to conclusions.\n",
    "\n",
    "For each feature in the dataset, compare its distribution in the treated group with its distribution in the control group, using plots and numbers.\n",
    "As above, you may use the techniques we discussed in class for summarizing and comparing the distributions.\n",
    "\n",
    "What do you observe?\n",
    "Describe what your observations mean for the conclusions drawn by the naive \"researcher\" from his superficial analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))\n",
    "\n",
    "ax[0, 0].set_title(\"No Degree repartition\")\n",
    "sns.countplot(x='treat', hue='nodegree', data=df, ax=ax[0, 0])\n",
    "\n",
    "ax[0, 1].set_title(\"Marital status repartition\")\n",
    "sns.countplot(x='treat', hue='married', data=df, ax=ax[0,1])\n",
    "\n",
    "ax[1, 0].set_title(\"Age distribution\")\n",
    "sns.violinplot(x='treat', y='age', data=df, ax=ax[1, 0])\n",
    "\n",
    "ax[1, 1].set_title(\"Education distribution\")\n",
    "sns.violinplot(x='treat', y='educ', data=df, ax=ax[1, 1])\n",
    "\n",
    "ax[2, 0].set_title(\"Race repartition\")\n",
    "sns.countplot(x='treat', hue='race', data=df, ax=ax[2, 0])\n",
    "\n",
    "ax[2, 1].set_title(\"Race repartition for non white people\")\n",
    "sns.countplot(x='treat', hue='race', data=df.loc[df.race != 'white', ['treat', 'race']], ax=ax[2, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following observations can be made:\n",
    "- There are almost no married people in the treated group.\n",
    "- The study seems to prefer more aged people for the treated group. The education is fairly similar in both groups\n",
    "- We see a clear racial bias in the design of the study: there are almost no white people in treated group and an overweighing proportion of black people in treated group.\n",
    "\n",
    "As the means seem to suggest, the salaries for the treated group are still lower than the control group after treatment, thus one could be led to believe that the treadment is inefficient:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Means of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mean_group = df.groupby('treat').mean().round(2)\n",
    "df_mean_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, looking at the _differences_ between the treated and non-treated groups, we see that they become smaller after treatment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of revenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_t_nt_74 = df_mean_group.loc[0].re74 - df_mean_group.loc[1].re74\n",
    "diff_t_nt_75 = df_mean_group.loc[0].re75 - df_mean_group.loc[1].re75\n",
    "diff_t_nt_78 = df_mean_group.loc[0].re78 - df_mean_group.loc[1].re78\n",
    "print(\"Difference between groups in 1974: \" + str(np.round(diff_t_nt_74,2)))\n",
    "print(\"Difference between groups in 1975: \" + str(np.round(diff_t_nt_75,2)))\n",
    "print(\"Difference between groups in 1978: \" + str(np.round(diff_t_nt_78,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the difference between the groups got smaller from 1974 to 1978, although salaries got higher on avarage for both groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the histograms of the distribution of revenues rounded to the closest thousand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_x = df.loc[df.treat == 1, 're78'].values.round(-3)\n",
    "control_x = df.loc[df.treat == 0, 're78'].values.round(-3)\n",
    "\n",
    "x_treated, y_treated = np.unique(treated_x, return_counts=True)\n",
    "x_treated = (x_treated/1000).astype(int)\n",
    "\n",
    "x_control, y_control = np.unique(control_x, return_counts=True)\n",
    "x_control = (x_control/1000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_histogram(df, columns, treated, title, legend, figsize=(20,10), counts = False):\n",
    "    \"\"\"\n",
    "    This functions plots a histogram adding the values on top of the bins.\n",
    "\n",
    "    x: values of the attribute that is being counted\n",
    "    y: counts of the x values\n",
    "    title: title to give to the histogram\n",
    "    abscissa: absissa to be displayed (what is being counted)\n",
    "    \"\"\"    \n",
    "    color = cm.RdGy(np.linspace(0, 1, 4))\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
    "    width = figsize[0]/100*(len(columns)+len(treated))/2 # the width of the bars\n",
    "    offset = figsize[0]/50 # distance between two bars\n",
    "\n",
    "    i = 0\n",
    "    for t in treated:\n",
    "        for c in columns:\n",
    "            \n",
    "            \n",
    "            if counts == True:\n",
    "                x, y = np.unique(df.loc[df.treat == t, c],return_counts = True)\n",
    "                y = y/ len(df[df.treat == t])\n",
    "                \n",
    "                ind = np.arange(len(y))\n",
    "                #ind = ['true','false']\n",
    "            else:\n",
    "                x_treated = df.loc[df.treat == t, c].values.round(-3)\n",
    "                x_treated, y = np.unique(x_treated, return_counts=True)\n",
    "                y = y/len(df.loc[df.treat == t, c])\n",
    "                x = (x_treated/1000).astype(int)\n",
    "                ind = np.arange(len(y))\n",
    "            ax.bar(ind + offset*i, y, width, color=color[i])\n",
    "            ax.set_xticks(ind)\n",
    "            ax.set_xticklabels(x, minor=False)\n",
    "\n",
    "\n",
    "            #for j, v in enumerate(y):\n",
    "            #    ax.text(j-width/6, v + 1, str(v), color=color[i])\n",
    "            i = i + 1\n",
    "        \n",
    "    fig.suptitle(title, fontsize=15)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Revenue')\n",
    "    plt.ylabel('Percentage of population')\n",
    "    plt.legend(legend)\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, ['re75'], [0,1], legend = ['non-treated','treated'], title='Revenue in 1975 (x1000)', figsize=(15,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, ['re78'], [0,1], legend = ['non-treated','treated'], title='Revenue in 1978 (x1000)', figsize=(15,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These histograms are slightly difficult to read but they suggest that treated more individuals of treated groups were in lower-salary classes in 1975 while in 1978 (after treatment) the difference between the treated and control group is weaker.\n",
    "\n",
    "Globally, we can also visualize the correlation between variables, and especially the correlation between the assignment to the treat group and other variables (first column):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_matrix(df, mask_diag=True, f_size=(6,5)):\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=f_size)\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    if mask_diag:\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    sns.heatmap(corr, mask=mask, cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "                square=True, ax=ax, annot=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_corr_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix confirms the assumption that `black` and `married` are two features that are correlated with `treat`. There is also a weak correlation (`-0.25`) between the revenues in 1974 and the assignment. Black, unmarried people with low salaries are thus more likely to be in the control group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. A propensity score model\n",
    "\n",
    "Use logistic regression to estimate propensity scores for all points in the dataset.\n",
    "You may use `sklearn` to fit the logistic regression model and apply it to each data point to obtain propensity scores:\n",
    "\n",
    "```python\n",
    "from sklearn import linear_model\n",
    "logistic = linear_model.LogisticRegression()\n",
    "```\n",
    "\n",
    "Recall that the propensity score of a data point represents its probability of receiving the treatment, based on its pre-treatment features (in this case, age, education, pre-treatment income, etc.).\n",
    "To brush up on propensity scores, you may read chapter 3.3 of the above-cited book by Rosenbaum or [this article](https://drive.google.com/file/d/0B4jctQY-uqhzTlpBaTBJRTJFVFE/view).\n",
    "\n",
    "Note: you do not need a train/test split here. Train and apply the model on the entire dataset. If you're wondering why this is the right thing to do in this situation, recall that the propensity score model is not used in order to make predictions about unseen data. Its sole purpose is to balance the dataset across treatment groups.\n",
    "(See p. 74 of Rosenbaum's book for an explanation why slight overfitting is even good for propensity scores.\n",
    "If you want even more information, read [this article](https://drive.google.com/file/d/0B4jctQY-uqhzTlpBaTBJRTJFVFE/view).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following people seem to have been favoured for treatment\n",
    "- Black people (84% proportion treated vs 20% proportion non-treated);\n",
    "- Unmarried people (19% vs 60%);\n",
    "- People with lower incomes in 1974 in particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic model to compute propensity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As \"pre-treatment\" features, we select all the given features except for `treat` and `re78` (outcome variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "clf = linear_model.LogisticRegression()\n",
    "\n",
    "# prepare the data\n",
    "# discard non pre-treatment features\n",
    "X = np.asarray(df.drop(['treat','re78', 'race'], axis=1).values)\n",
    "# get the labels\n",
    "y = np.asarray(df['treat'].values)\n",
    "\n",
    "# fit the logistic regression classifier\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the propensity scores : the prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the probabilty that predicted label is 1 (treatement) (the propensity scores)\n",
    "prop_scores = clf.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert probabilities to corresponding points in dataframe\n",
    "df['propensity_score'] = prop_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='treat', y='propensity_score', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that the propensity scores of the treated group are way higher than the one of the control group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Balancing the dataset via matching\n",
    "\n",
    "_Use the propensity scores to match each data point from the treated group with exactly one data point from the control group, while ensuring that each data point from the control group is matched with at most one data point from the treated group.\n",
    "(Hint: you may explore the `networkx` package in Python for predefined matching functions.)_\n",
    "\n",
    "_Your matching should maximize the similarity between matched subjects, as captured by their propensity scores.\n",
    "In other words, the sum (over all matched pairs) of absolute propensity-score differences between the two matched subjects should be minimized._\n",
    "\n",
    "_After matching, you have as many treated as you have control subjects.\n",
    "Compare the outcomes (`re78`) between the two groups (treated and control)._\n",
    "\n",
    "_Also, compare again the feature-value distributions between the two groups, as you've done in part 2 above, but now only for the matched subjects.\n",
    "What do you observe?\n",
    "Are you closer to being able to draw valid conclusions now than you were before?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a bipartite graph whose left nodes contain the indexes of people having been treated and as a right nodes contain indexes of people who have not been treated. We will connect all left and right nodes by the weight, which we calculate as the absolute difference between their propensities to be treated. Since `networkx` offers no way to minimize the weights, we will simply take the negative difference and then maximize the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_control = df.index[df['treat']==0]\n",
    "nodes_treated = df.index[df['treat']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['treat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a bipartite graph by adding control nodes and treated nodes. The edges between the two sides are weighted by **minus** the absolute difference of propensity scores. Indeed, we then look for a Max weight matching of the bipartite graph so that will be the matching minimizing the sum of **plus** absolute differences of propensity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.Graph()\n",
    "\n",
    "# add nodes\n",
    "B.add_nodes_from(nodes_treated, bipartite = 0)\n",
    "B.add_nodes_from(nodes_control, bipartite = 1)\n",
    "\n",
    "# add edges and weights\n",
    "for ind_treated, node_treated in enumerate(nodes_treated):\n",
    "    for ind_control, node_control in enumerate(nodes_control):\n",
    "        propensity_diff = -abs(prop_scores[y==1][ind_treated] - prop_scores[y==0][ind_control])\n",
    "        B.add_edge(node_treated, node_control, weight = propensity_diff)\n",
    "\n",
    "print(\"Graph is fully connected: \" + str(nx.is_connected(B)))\n",
    "print(nx.is_bipartite(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of nodes: {}'.format(len(B.nodes())))\n",
    "print('Number of edges: {}'.format(len(B.edges())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: the total number of nodes in the graph corresponds to the total rows in the DataFrame and the number of edges is the product of the sizes of treat and control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_matching = nx.bipartite.maximum_matching(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionnary `max_matching` contains the matching in both ways. We want to keep only the keys that belong to the treat group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = {}\n",
    "for key in max_matching.keys():\n",
    "    if df.loc[key, 'treat'] == 1:\n",
    "        matching[key] = max_matching[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the length of the matching is the minimum of the size of treat and control group. This seems legit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO show propensity to be treated for both groups\n",
    "df['match_treat'] = -1\n",
    "df.loc[matching.keys(),'match_treat'] = 1\n",
    "df.loc[matching.values(),'match_treat'] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df.loc[df.match_treat != -1]\n",
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))\n",
    "\n",
    "ax[0, 0].set_title(\"No Degree repartition\")\n",
    "sns.countplot(x='match_treat', hue='nodegree', data=df_tmp, ax=ax[0, 0])\n",
    "\n",
    "ax[0, 1].set_title(\"Marital status repartition\")\n",
    "sns.countplot(x='match_treat', hue='married', data=df_tmp, ax=ax[0,1])\n",
    "\n",
    "ax[1, 0].set_title(\"Age distribution\")\n",
    "sns.violinplot(x='match_treat', y='age', data=df_tmp, ax=ax[1, 0])\n",
    "\n",
    "ax[1, 1].set_title(\"Education distribution\")\n",
    "sns.violinplot(x='match_treat', y='educ', data=df_tmp, ax=ax[1, 1])\n",
    "\n",
    "ax[2, 0].set_title(\"Race repartition\")\n",
    "sns.countplot(x='match_treat', hue='race', data=df_tmp, ax=ax[2, 0])\n",
    "\n",
    "ax[2, 1].set_title(\"Race repartition for non white people\")\n",
    "sns.countplot(x='match_treat', hue='race', data=df_tmp.loc[df.race != 'white', ['match_treat', 'race']], ax=ax[2, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marital statues and race repartition are still not balanced. This need to be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propensity scores for both groups are not balanced either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df.loc[df.match_treat == 0, 'propensity_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(df.loc[df.match_treat == 1, 'propensity_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Balancing the groups further\n",
    "\n",
    "Based on your comparison of feature-value distributions from part 4, are you fully satisfied with your matching?\n",
    "Would you say your dataset is sufficiently balanced?\n",
    "If not, in what ways could the \"balanced\" dataset you have obtained still not allow you to draw valid conclusions?\n",
    "\n",
    "Improve your matching by explicitly making sure that you match only subjects that have the same value for the problematic feature.\n",
    "Argue with numbers and plots that the two groups (treated and control) are now better balanced than after part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing as before but now we only add edges between the nodes that have the same race and the same marital status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.Graph()\n",
    "\n",
    "# add nodes\n",
    "B.add_nodes_from(nodes_treated, bipartite = 0)\n",
    "B.add_nodes_from(nodes_control, bipartite = 1)\n",
    "\n",
    "# add edges and weights\n",
    "for ind_treated, node_treated in enumerate(nodes_treated):\n",
    "    for ind_control, node_control in enumerate(nodes_control):\n",
    "        if df.loc[node_treated, 'race'] == df.loc[node_control, 'race'] and df.loc[node_treated, 'married'] == df.loc[node_control, 'married']:\n",
    "            propensity_diff = -abs(prop_scores[y==1][ind_treated] - prop_scores[y==0][ind_control])\n",
    "            B.add_edge(node_treated, node_control, weight = propensity_diff)\n",
    "\n",
    "print(nx.is_connected(B))\n",
    "print(nx.is_bipartite(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is not connected anymore. Let's see if each node as at least one neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.isolate.number_of_isolates(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No node is isolated so we will be able to find a matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "In order to use network x, we need to make the graph connected again. Let's do so by making control and test subgraphs complete (with inner edge weights $\\infty$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. A less naive analysis\n",
    "\n",
    "Compare the outcomes (`re78`) between treated and control subjects, as you've done in part 1, but now only for the matched dataset you've obtained from part 5.\n",
    "What do you conclude about the effectiveness of the job training program?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Applied ML\n",
    "\n",
    "We are going to build a classifier of news to directly assign them to 20 news categories. Note that the pipeline that you will build in this exercise could be of great help during your project if you plan to work with text!\n",
    "\n",
    "1. Load the 20newsgroup dataset. It is, again, a classic dataset that can directly be loaded using sklearn ([link](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html)).  \n",
    "[TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), short for term frequency–inverse document frequency, is of great help when if comes to compute textual features. Indeed, it gives more importance to terms that are more specific to the considered articles (TF) but reduces the importance of terms that are very frequent in the entire corpus (IDF). Compute TF-IDF features for every article using [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Then, split your dataset into a training, a testing and a validation set (10% for validation and 10% for testing). Each observation should be paired with its corresponding label (the article category).\n",
    "\n",
    "2. Train a random forest on your training set. Try to fine-tune the parameters of your predictor on your validation set using a simple grid search on the number of estimator \"n_estimators\" and the max depth of the trees \"max_depth\". Then, display a confusion matrix of your classification pipeline. Lastly, once you assessed your model, inspect the `feature_importances_` attribute of your random forest and discuss the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(mat):\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(mat, cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the df-idf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "# compute the td-idf features\n",
    "tfidf = vectorizer.fit_transform(newsgroups_train['data'])\n",
    "# get the correspondance between features and words\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data set in train, test and validation tests (80%, 10%, 10%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in train (80%) and tmp (20%)\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(tfidf, newsgroups_train['target'], test_size=0.2, random_state=42)\n",
    "# split tmp in test and validation (50% - 50%) ~ (10% - 10%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the random forest\n",
    "\n",
    "First we use the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on test and visualize confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "plot_confusion_matrix(np.asarray(confusion_matrix(y_test, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':[10, 30, 50, 100, 200], 'max_depth':[10, 20, 50, 100, 200]}\n",
    "grid_search = GridSearchCV(clf, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_val, y_val)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test of the classifier with these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200, max_depth=50)\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "plot_confusion_matrix(np.asarray(confusion_matrix(y_test, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix shows that the prediction is far more accurate using the tuned hyperparameters found by grid search.\n",
    "Blue is darker outside of the diagonal (less errors of classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance\n",
    "\n",
    "Now let's look at the `feature_importances_` of the classifier and see the correspondance with terms in the text.\n",
    "\n",
    "We'll look at the 20 more important features and the corresponding terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = list(np.argsort(clf.feature_importances_)[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itemgetter(*ind)(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- discuss the results\n",
    "- improve classifications by doing data cleaning (tokenization ?)\n",
    "- compute score of classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
